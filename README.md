# GitHub Copilot Workshop (Codespace Edition)

Welcome to the **GitHub Copilot Hands-On Workshop**! In this session, you'll explore how to use Copilot inside a GitHub Codespace to boost productivity and write smarter code to support various steps of long range transportation plan (LRTP)

---

## Setup Instructions

1. **Open this repo in GitHub Codespaces:**
   - Click the green `Code` button
   - Choose `Codespaces` > `Create codespace on main`

2. **Wait for the environment to load (1–2 mins)**
   - Python 3.11, Jupyter, and Copilot extensions are pre-installed

3. **Ensure Copilot is enabled**
   - You must have an active Copilot license (trial, student, or enterprise)
   - Sign in if prompted and allow Copilot permissions

---

## Workshop Activities

Following are the list of activities that are related to various steps during the development of LRTP process.
You can follow the activities in the notebook or directly in the script files:

##### 1. `scripts/1.1 clean_lrtp_inputs.py`
- This script marks the beginning of the LRTP pipeline, where raw data is collected and prepared for analysis. The datasets involved typically include socio-economic data, land use patterns, travel behavior surveys, and roadway or transit networks. Since this data often comes from different sources and formats, it tends to be messy and inconsistent. This script focuses on tasks like renaming columns, dropping missing or duplicate values, converting data types, and applying filters to remove outliers or irrelevant entries. With GitHub Copilot, you can streamline much of this process by writing comments like “# drop rows with missing values” or “# convert date to datetime,” and Copilot will suggest functional code that executes those cleaning steps efficiently.

##### 2. `scripts/2.1 trip_generation_distribution.py`
- Once the input data is cleaned, the next step is to estimate how many trips are produced and attracted in each zone and how these trips are distributed spatially. This script implements a basic version of the trip generation and distribution steps commonly found in travel demand models. It may use regression models, growth factors, or other rules to calculate the number of trips generated by households or jobs. Then, it distributes these trips between origin and destination zones using a simplified gravity model or proportional distribution. GitHub Copilot proves useful here by auto-suggesting formulas, loop structures, or vectorized operations that implement these modeling steps more quickly.

##### 3. `scripts/2.2 summarize_model_output.py`
- After generating the travel demand, this script is used to process and summarize the outputs of the model. The outputs od travel emand model could include detailed origin-destination trip matrices, loaded volumes on network links, or travel time skims. The goal here is to extract meaningful insights such as regional vehicle miles traveled (VMT) or average delay. Copilot enhances this workflow by providing quick code snippets for operations like “group by zone/corridors and sum trips” making data summarization smoother and faster. 

##### 4. `scripts/2.3 calculate_avg_trip_length.py`
- This script focuses on a specific and important metric—average trip length—which is useful for understanding network efficiency and travel behavior. It typically joins trip data with distance or travel time matrices and then calculates a weighted average trip length across all trips. This can be done for different scenarios, time periods, or user groups. Copilot helps automate the merging of datasets, filtering of invalid records, and calculation of the weighted average, often suggesting full function definitions from just a short comment.

##### 5. `scripts/3.1 generate_scenario_inputs.py`
- Scenarios are the heart of long-range transportation planning. This script automates the creation of future-year or alternative scenario input files. For instance, you might take 2023 population data and apply regional growth rates to estimate 2050 values. Or you might add new road segments or transit lines to represent a proposed infrastructure investment. This script applies those growth factors or edits and saves the modified data for use in travel demand models. Copilot can make these repetitive tasks easier by suggesting transformation code as soon as you describe the goal in plain language—for example, “# increase employment by 25% for future scenario.”

##### 6. `scripts/4.1 project_eval.py`
- This script shifts the focus from modeling to evaluation. After model runs are complete, planners need to understand how each scenario performs against key indicators such as emissions, accessibility, equity, and congestion. This script helps with those assessments by importing modeled metrics and comparing them across scenarios or geography. It often includes charts, summary tables, and metrics like average travel time or CO₂ emissions per capita. With Copilot, you can speed up the generation of these summaries and visuals by simply writing descriptive comments like “# plot emissions by scenario,” and letting Copilot generate a well-formed visualization block.

##### 6. `scripts/5.1 visualize_scenarios.py`
- Effective communication is critical for LRTPs, and this script focuses on preparing visual outputs for stakeholders and the public. These include bar charts comparing performance measures across scenarios. The goal is to turn technical model results into engaging visuals. With Copilot, you can use plain English prompts like “# plot accessibility by TAZ as a heatmap” and receive useful code to build such visuals, even if you're less familiar with plotting libraries like Seaborn, Matplotlib, or Folium.

##### 6. `scripts/6.1 generate_markdown_summary.py`
- Here, we focus on turning raw analysis into narrative summaries for inclusion in presentations or reports. This notebook takes performance metrics and produces structured Markdown summaries that describe scenario outcomes in plain language. For instance, it might output a sentence like “Scenario B reduced average CO₂ emissions by 15% compared to the NoBuild scenario.” Copilot is very effective in this context—especially when you write a prompt like “# write summary of accessibility improvements”—as it can suggest coherent Markdown text based on your computed variables.

---

## Data File

The folder `data/` contains:
- `scenario_inputs_raw.csv`: Sample socio-economic data uncleaned version
- `zonal_data.csv`: Clean zonal data
- `model_output.csv`: Mock TAZ-level model output
- `od_trips_with_distance.csv`: Trips between origin and destination TAZ
- `project_eval_results.csv`: Evaluation meterics for each TAZ and for each scenario

---

## Tips

- Use **natural language comments** to guide Copilot
- Accept, modify, or reject suggestions as needed
- Don't forget to review generated code critically

---

Happy coding!
